{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Cosmo-ML-Tools","text":""},{"location":"#a-cosmology-machine-learning-toolbox","title":"A Cosmology &amp; Machine Learning Toolbox","text":"<p>An attempt to wrap many useful python packagages, ML algorithms and automate common workflows in Cosmology.</p> <p>DISCLAIMER: This is very much work in progress. It is originally intended for my own use, so the documentation might not be as good as I would like it to be.</p> <ul> <li>Free software: MIT License</li> <li>Documentation: https://rcalderonb6.github.io/cosmo-ml-tools</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>TODO</li> </ul>"},{"location":"analysis/","title":"Analysis module","text":""},{"location":"analysis/#cosmo_ml_tools.analysis.chain.CobayaChain","title":"<code> CobayaChain            (MHChain)         </code>","text":"Source code in <code>cosmo_ml_tools/analysis/chain.py</code> <pre><code>class CobayaChain(MHChain):\n\n    def to_harmonic(self,ndim:int,N:int):\n        return convert_to_harmonic(self.filename,ndim,N=N,sampler='cobaya')\n</code></pre>"},{"location":"analysis/#cosmo_ml_tools.analysis.chain.CobayaChain.to_harmonic","title":"<code>to_harmonic(self, ndim, N)</code>","text":"<p>A method that returns the samples and corresponding posterior values in a Harmonic-friendly format.</p> Source code in <code>cosmo_ml_tools/analysis/chain.py</code> <pre><code>def to_harmonic(self,ndim:int,N:int):\n    return convert_to_harmonic(self.filename,ndim,N=N,sampler='cobaya')\n</code></pre>"},{"location":"analysis/#cosmo_ml_tools.analysis.chain.MHChain","title":"<code> MHChain            (ChainBase)         </code>","text":"<p>Metropolis-Hastings Base Class</p> Source code in <code>cosmo_ml_tools/analysis/chain.py</code> <pre><code>class MHChain(ChainBase):    \n    \"\"\"\n    Metropolis-Hastings Base Class\n    \"\"\"\n    def load(self,engine:str='getdist'):\n        \"\"\"Load the chain using the specified Engine. Defaults to Getdist.\n\n        Args:\n            engine (str, optional): choice analysis engine. Engines that are currently implemented include: ['getdist'] Defaults to 'getdist'. TODO: include compatibility with `chainconsumer` and `anesthaetic`\n        Raises:\n            NotImplementedError: If the engine is not yet implemented\n\n        Returns:\n            Samples: an instance of the Samples class.\n        \"\"\"\n        if engine=='getdist':\n            return loadMCSamples(self._root+self.fn,self.gd_settings)\n        else:\n            raise NotImplementedError\n\n    def to_harmonic(self):\n        return NotImplementedError\n\n    def getInfo(self):\n        return NotImplementedError    \n\n    def getTable(self, params: list):\n        return NotImplementedError\n\n    def set_param_labels(self,labels:list[str]):\n        return NotImplementedError\n</code></pre>"},{"location":"analysis/#cosmo_ml_tools.analysis.chain.MHChain.getInfo","title":"<code>getInfo(self)</code>","text":"<p>Print a summary of useful information on the chain.</p> Source code in <code>cosmo_ml_tools/analysis/chain.py</code> <pre><code>def getInfo(self):\n    return NotImplementedError    \n</code></pre>"},{"location":"analysis/#cosmo_ml_tools.analysis.chain.MHChain.getTable","title":"<code>getTable(self, params)</code>","text":"<p>Print a latex table with the mean and 68% CL.</p> Source code in <code>cosmo_ml_tools/analysis/chain.py</code> <pre><code>def getTable(self, params: list):\n    return NotImplementedError\n</code></pre>"},{"location":"analysis/#cosmo_ml_tools.analysis.chain.MHChain.load","title":"<code>load(self, engine='getdist')</code>","text":"<p>Load the chain using the specified Engine. Defaults to Getdist.</p> <p>Parameters:</p> Name Type Description Default <code>engine</code> <code>str</code> <p>choice analysis engine. Engines that are currently implemented include: ['getdist'] Defaults to 'getdist'. TODO: include compatibility with <code>chainconsumer</code> and <code>anesthaetic</code></p> <code>'getdist'</code> <p>Exceptions:</p> Type Description <code>NotImplementedError</code> <p>If the engine is not yet implemented</p> <p>Returns:</p> Type Description <code>Samples</code> <p>an instance of the Samples class.</p> Source code in <code>cosmo_ml_tools/analysis/chain.py</code> <pre><code>def load(self,engine:str='getdist'):\n    \"\"\"Load the chain using the specified Engine. Defaults to Getdist.\n\n    Args:\n        engine (str, optional): choice analysis engine. Engines that are currently implemented include: ['getdist'] Defaults to 'getdist'. TODO: include compatibility with `chainconsumer` and `anesthaetic`\n    Raises:\n        NotImplementedError: If the engine is not yet implemented\n\n    Returns:\n        Samples: an instance of the Samples class.\n    \"\"\"\n    if engine=='getdist':\n        return loadMCSamples(self._root+self.fn,self.gd_settings)\n    else:\n        raise NotImplementedError\n</code></pre>"},{"location":"analysis/#cosmo_ml_tools.analysis.chain.MHChain.set_param_labels","title":"<code>set_param_labels(self, labels)</code>","text":"<p>Set the labels for the parameters</p> Source code in <code>cosmo_ml_tools/analysis/chain.py</code> <pre><code>def set_param_labels(self,labels:list[str]):\n    return NotImplementedError\n</code></pre>"},{"location":"analysis/#cosmo_ml_tools.analysis.chain.MHChain.to_harmonic","title":"<code>to_harmonic(self)</code>","text":"<p>A method that returns the samples and corresponding posterior values in a Harmonic-friendly format.</p> Source code in <code>cosmo_ml_tools/analysis/chain.py</code> <pre><code>def to_harmonic(self):\n    return NotImplementedError\n</code></pre>"},{"location":"analysis/#cosmo_ml_tools.analysis.chain.MontePythonChain","title":"<code> MontePythonChain            (MHChain)         </code>","text":"Source code in <code>cosmo_ml_tools/analysis/chain.py</code> <pre><code>class MontePythonChain(MHChain):\n\n    def to_harmonic(self,ndim:int,N:int):\n        return convert_to_harmonic(self.filename,ndim,N=N,sampler='montepython')\n</code></pre>"},{"location":"analysis/#cosmo_ml_tools.analysis.chain.MontePythonChain.to_harmonic","title":"<code>to_harmonic(self, ndim, N)</code>","text":"<p>A method that returns the samples and corresponding posterior values in a Harmonic-friendly format.</p> Source code in <code>cosmo_ml_tools/analysis/chain.py</code> <pre><code>def to_harmonic(self,ndim:int,N:int):\n    return convert_to_harmonic(self.filename,ndim,N=N,sampler='montepython')\n</code></pre>"},{"location":"analysis/#cosmo_ml_tools.analysis.chain.NSChain","title":"<code> NSChain            (ChainBase)         </code>","text":"<p>Nested-Sampling Base Class.</p> Source code in <code>cosmo_ml_tools/analysis/chain.py</code> <pre><code>class NSChain(ChainBase):\n    \"\"\"\n    Nested-Sampling Base Class.\n    \"\"\"\n    pass    \n</code></pre>"},{"location":"analysis/#cosmo_ml_tools.analysis.chain.convert_to_harmonic","title":"<code>convert_to_harmonic(chain_fn, ndim, N=4, sampler='cobaya', ignore=0.3)</code>","text":"<p>Helper function to convert a set of chains into a Harmonic-friendly format</p> <p>Parameters:</p> Name Type Description Default <code>chain_fn</code> <code>str</code> <p>the location of the chains on the disk, where chain_fn is the root for all the chains (and .param_names files)</p> required <code>ndim</code> <code>int</code> <p>Number of sampled (free parameters)</p> required <code>N</code> <code>int</code> <p>Number of chains {chain_fn}__i.txt with i from 1 to N. Defaults to 4.</p> <code>4</code> <code>sampler</code> <code>str</code> <p>specifies sampler used to compute the samples, useful for the format. Defaults to 'cobaya'.</p> <code>'cobaya'</code> <code>ignore</code> <code>float</code> <p>The fraction of samples to reject as burn-in. Defaults to 0.3.</p> <code>0.3</code> <p>Returns:</p> Type Description <code>tuple[list,list]</code> <p>a tuple with the samples and log-posterior values in a Harmonic-compatible format</p> Source code in <code>cosmo_ml_tools/analysis/chain.py</code> <pre><code>def convert_to_harmonic(chain_fn:str,ndim:int,N:int=4,sampler:str='cobaya',ignore:float=0.3)-&gt; tuple[list,list]:\n    \"\"\"Helper function to convert a set of chains into a Harmonic-friendly format\n\n    Args:\n        chain_fn (str): the location of the chains on the disk, where chain_fn is the root for all the chains (and .param_names files)\n        ndim (int): Number of sampled (free parameters)\n        N (int, optional): Number of chains {chain_fn}__i.txt with i from 1 to N. Defaults to 4.\n        sampler (str, optional): specifies sampler used to compute the samples, useful for the format. Defaults to 'cobaya'.\n        ignore (float, optional): The fraction of samples to reject as burn-in. Defaults to 0.3.\n\n    Returns:\n        tuple[list,list]: a tuple with the samples and log-posterior values in a Harmonic-compatible format\n    \"\"\"\n    #Load individual chains\n    chains={f'chain{i}': np.loadtxt(f'{chain_fn}.{i}.txt') for i in range(1,N)}\n\n    # Determine the smaller of them and determine burn-in\n    min_len=np.min([chain.shape[0] for chain in chains.values()])\n    burn_in=int(ignore * min_len)\n\n    # Reshape them into harmonic-friendly format\n    if sampler=='cobaya':\n        samples=np.array([chain[burn_in:min_len,2:ndim+2] for chain in chains.values()]).reshape((N,min_len-burn_in,ndim))\n        lnprob=-np.array([chain[burn_in:min_len,1] for chain in chains.values()]).reshape((N,min_len-burn_in))\n\n    #TODO: Implement Montepython compatibility (Should check which columns give lnprob and whether the sampled params are first)\n    elif sampler=='montepython':\n        print('Sorry, Montepython not yet implemented!')\n        return\n\n    else:\n        print('Sorry, sampler not recognized or not yet implemented!')\n        return\n\n    return samples, lnprob\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v001-date","title":"v0.0.1 - Date","text":"<p>Improvement:</p> <ul> <li>TBD</li> </ul> <p>New Features:</p> <ul> <li>TBD</li> </ul>"},{"location":"common/","title":"common module","text":"<p>The common module contains common functions and classes used by the other modules.</p>"},{"location":"common/#cosmo_ml_tools.common.bye_world","title":"<code>bye_world()</code>","text":"<p>Prints \"Bye World!\" to the console.</p> Source code in <code>cosmo_ml_tools/common.py</code> <pre><code>def bye_world():\n    \"\"\"Prints \"Bye World!\" to the console.\n    \"\"\"\n    print(\"Bye World!\")\n</code></pre>"},{"location":"common/#cosmo_ml_tools.common.hello_world","title":"<code>hello_world()</code>","text":"<p>Prints \"Hello World!\" to the console.</p> Source code in <code>cosmo_ml_tools/common.py</code> <pre><code>def hello_world():\n    \"\"\"Prints \"Hello World!\" to the console.\n    \"\"\"\n    print(\"Hello World!\")\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/rcalderonb6/cosmo-ml-tools/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>cosmo-ml-tools could always use more documentation, whether as part of the official cosmo-ml-tools docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/rcalderonb6/cosmo-ml-tools/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up cosmo_ml_tools for local development.</p> <ol> <li> <p>Fork the cosmo_ml_tools repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/cosmo-ml-tools.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv cosmo_ml_tools\n$ cd cosmo_ml_tools/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 cosmo_ml_tools tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.8 and later, and     for PyPy. Check https://github.com/rcalderonb6/cosmo-ml-tools/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"cosmo_ml_tools/","title":"cosmo_ml_tools module","text":"<p>Main module.</p>"},{"location":"cosmology/","title":"Cosmology module","text":"<p>Cosmology module.</p>"},{"location":"faq/","title":"FAQ","text":""},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install cosmo-ml-tools, run this command in your terminal:</p> <pre><code>pip install cosmo-ml-tools\n</code></pre> <p>This is the preferred method to install cosmo-ml-tools, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-sources","title":"From sources","text":"<p>To install cosmo-ml-tools from sources, run this command in your terminal:</p> <pre><code>pip install git+https://github.com/rcalderonb6/cosmo-ml-tools\n</code></pre>"},{"location":"plots/","title":"Plotting module","text":"<p>The <code>plots</code> module of <code>cosmo-ml-tools</code> contains useful scripts and visualization tools to produce publication-quality plots. </p> <p>Plotting module.</p>"},{"location":"quickstart/","title":"A Quickstart on some of the features of Cosmo-ML-Tools","text":""},{"location":"sampler/","title":"Sampler module","text":"<p>Sampler Module.</p>"},{"location":"sampler/#cosmo_ml_tools.sampler.base","title":"<code>base</code>","text":""},{"location":"sampler/#cosmo_ml_tools.sampler.base.MCBase","title":"<code> MCBase            (ABC)         </code>","text":"<p>Abstract Monte Carlo Base Class</p> Source code in <code>cosmo_ml_tools/sampler/base.py</code> <pre><code>class MCBase(ABC):\n    \"\"\"Abstract Monte Carlo Base Class\"\"\"\n    def __init__(self):\n        pass\n\n    @abstractmethod\n    def run(self,*args,**kwargs):\n        \"\"\"\n        Start the sampling process\n        \"\"\"\n        ...\n\n    @abstractmethod \n    def resume(self,*args,**kwargs):\n        \"\"\"\n        Resume the sampling process\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def trace(self,params:list,*args,**kwargs):\n        \"\"\"\n        Produce a trace plot of the chain. i.e. the evolution of the parameter values as a function of step number\n\n        Args:\n            params (list): A list of parameters to plot.\n\n        Returns:\n            fig: An instance of the matplotlib class\n        \"\"\"\n        ...\n</code></pre>"},{"location":"sampler/#cosmo_ml_tools.sampler.base.MCBase.resume","title":"<code>resume(self, *args, **kwargs)</code>","text":"<p>Resume the sampling process</p> Source code in <code>cosmo_ml_tools/sampler/base.py</code> <pre><code>@abstractmethod \ndef resume(self,*args,**kwargs):\n    \"\"\"\n    Resume the sampling process\n    \"\"\"\n    ...\n</code></pre>"},{"location":"sampler/#cosmo_ml_tools.sampler.base.MCBase.run","title":"<code>run(self, *args, **kwargs)</code>","text":"<p>Start the sampling process</p> Source code in <code>cosmo_ml_tools/sampler/base.py</code> <pre><code>@abstractmethod\ndef run(self,*args,**kwargs):\n    \"\"\"\n    Start the sampling process\n    \"\"\"\n    ...\n</code></pre>"},{"location":"sampler/#cosmo_ml_tools.sampler.base.MCBase.trace","title":"<code>trace(self, params, *args, **kwargs)</code>","text":"<p>Produce a trace plot of the chain. i.e. the evolution of the parameter values as a function of step number</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>list</code> <p>A list of parameters to plot.</p> required <p>Returns:</p> Type Description <code>fig</code> <p>An instance of the matplotlib class</p> Source code in <code>cosmo_ml_tools/sampler/base.py</code> <pre><code>@abstractmethod\ndef trace(self,params:list,*args,**kwargs):\n    \"\"\"\n    Produce a trace plot of the chain. i.e. the evolution of the parameter values as a function of step number\n\n    Args:\n        params (list): A list of parameters to plot.\n\n    Returns:\n        fig: An instance of the matplotlib class\n    \"\"\"\n    ...\n</code></pre>"},{"location":"stats/","title":"Statistics module","text":"<p>Statistics module.</p>"},{"location":"stats/#cosmo_ml_tools.stats.acquisition","title":"<code>acquisition</code>","text":""},{"location":"stats/#cosmo_ml_tools.stats.acquisition.ExpectedImprovement","title":"<code>ExpectedImprovement(rng_key, model, X, xi=0.01, maximize=False, n=1)</code>","text":"<p>Expected Improvement</p> Source code in <code>cosmo_ml_tools/stats/acquisition.py</code> <pre><code>def ExpectedImprovement(rng_key: jnp.ndarray, model: Type[GaussianProcessJax],\n       X: jnp.ndarray, xi: float = 0.01,\n       maximize: bool = False, n: int = 1) -&gt; jnp.ndarray:\n    \"\"\"\n    Expected Improvement\n    \"\"\"\n    y_mean, y_sampled = model.predict(rng_key, X, n=n)\n    if n &gt; 1:\n        y_sampled = y_sampled.reshape(n * y_sampled.shape[0], -1)\n    mean, sigma = y_sampled.mean(0), y_sampled.std(0)\n    u = (mean - y_mean.max() - xi) / sigma\n    u = -u if not maximize else u\n    normal = dist.Normal(jnp.zeros_like(u), jnp.ones_like(u))\n    ucdf = normal.cdf(u)\n    updf = jnp.exp(normal.log_prob(u))\n    return sigma * (updf + u * ucdf) \n</code></pre>"},{"location":"stats/#cosmo_ml_tools.stats.acquisition.ThompsonSampling","title":"<code>ThompsonSampling(rng_key, model, posterior_samples, X, n=1)</code>","text":"<p>Thompson sampling</p> Source code in <code>cosmo_ml_tools/stats/acquisition.py</code> <pre><code>def ThompsonSampling(rng_key: jnp.ndarray,\n             model: Type[GaussianProcessJax],\n             posterior_samples: Dict[str, jnp.ndarray],\n             X: jnp.ndarray, n: int = 1) -&gt; jnp.ndarray:\n    \"\"\"Thompson sampling\"\"\"\n    posterior_samples = model.get_samples()\n    idx = jra.randint(rng_key, (1,), 0, len(posterior_samples[\"k_length\"]))\n    samples = {k: v[idx] for (k, v) in posterior_samples.items()}\n    _, tsample = model.predict(rng_key, X, samples, n)\n    if n &gt; 1:\n        tsample = tsample.mean(1)\n    return tsample.squeeze()\n</code></pre>"},{"location":"stats/#cosmo_ml_tools.stats.acquisition.UncertaintyExploration","title":"<code>UncertaintyExploration(rng_key, model, X, n=1)</code>","text":"<p>Uncertainty-based exploration (aka kriging)</p> Source code in <code>cosmo_ml_tools/stats/acquisition.py</code> <pre><code>def UncertaintyExploration(rng_key: jnp.ndarray,\n       model: Type[GaussianProcessJax],\n       X: jnp.ndarray, n: int = 1) -&gt; jnp.ndarray:\n    \"\"\"Uncertainty-based exploration (aka kriging)\"\"\"\n    _, y_sampled = model.predict(rng_key, X, n=n)\n    return y_sampled.var(0)\n</code></pre>"},{"location":"stats/#cosmo_ml_tools.stats.acquisition.UpperConfidenceBound","title":"<code>UpperConfidenceBound(rng_key, model, X, beta=0.25, maximize=False, n=1)</code>","text":"<p>Upper confidence bound</p> Source code in <code>cosmo_ml_tools/stats/acquisition.py</code> <pre><code>def UpperConfidenceBound(rng_key: jnp.ndarray, model: Type[GaussianProcessJax],\n        X: jnp.ndarray, beta: float = .25,\n        maximize: bool = False, n: int = 1) -&gt; jnp.ndarray:\n    \"\"\"\n    Upper confidence bound\n    \"\"\"\n    _, y_sampled = model.predict(rng_key, X, n=n)\n    if n &gt; 1:\n        y_sampled = y_sampled.reshape(n * y_sampled.shape[0], -1)\n    mean, var= y_sampled.mean(0), y_sampled.var(0)\n    delta = jnp.sqrt(beta * var)\n    if maximize:\n        return mean + delta\n    return mean - delta \n</code></pre>"},{"location":"stats/#cosmo_ml_tools.stats.base","title":"<code>base</code>","text":""},{"location":"stats/#cosmo_ml_tools.stats.base.GaussianProcessBase","title":"<code> GaussianProcessBase            (ABC)         </code>","text":"<p>Gaussian Process Abstract Base class</p> Source code in <code>cosmo_ml_tools/stats/base.py</code> <pre><code>class GaussianProcessBase(ABC):\n    \"\"\"Gaussian Process Abstract Base class\"\"\"\n\n    def __init__(self):\n        pass\n\n    @abstractmethod\n    def fit(self):\n        ...\n\n    @abstractmethod\n    def predict(self,*args,**kwargs):\n        ...\n</code></pre>"},{"location":"stats/#cosmo_ml_tools.stats.base.LikelihoodBase","title":"<code> LikelihoodBase            (ABC)         </code>","text":"<p>Likelihood Abstract Base Class</p> Source code in <code>cosmo_ml_tools/stats/base.py</code> <pre><code>class LikelihoodBase(ABC):\n    \"\"\"Likelihood Abstract Base Class\"\"\"\n    def __init__(self,*args,**kwargs):\n        pass\n</code></pre>"},{"location":"stats/#cosmo_ml_tools.stats.gp","title":"<code>gp</code>","text":""},{"location":"stats/#cosmo_ml_tools.stats.gp.GaussianProcessJax","title":"<code> GaussianProcessJax            (GaussianProcessBase)         </code>","text":"Source code in <code>cosmo_ml_tools/stats/gp.py</code> <pre><code>class GaussianProcessJax(GaussianProcessBase):\n    def __init__(self, kernel, input_dim: int, mean_fn=None): \n        \"\"\"\n        Base Class implementing the usual Gaussian Process Regression algorithm. \n        The GP posterior is sampled using the Hamiltonian Monte Carlo 'No-U Turn' Sampler (NUTS) as implemented in numpyro\n        e.g. BaseGP(input_dim=2, kernel=RBFKernel)\n        \"\"\"\n        # clear_cache()\n        self.input_dim = input_dim\n        self.kernel = kernel\n        self.mean_fn = mean_fn\n        self.X_train = None\n        self.y_train = None\n        self.mcmc = None\n\n    def model(self, X, y):\n        \"\"\"GP model\"\"\"\n        # Initialize mean function at zeros\n        f_loc = jnp.zeros(X.shape[0])\n\n        # Sample kernel parameters and noise\n        with numpyro.plate('k_param', self.input_dim):  # allows using ARD kernel for input_dim &gt; 1\n            length = numpyro.sample(\"ell_f\", dist.LogNormal(0.0, 1.0))\n        scale = numpyro.sample(\"sigma_f\", dist.LogNormal(0.0, 1.0))\n        noise = numpyro.sample(\"noise\", dist.LogNormal(0.0, 1.0))\n\n        # Add mean function (if any)\n        if self.mean_fn is not None:\n            f_loc += self.mean_fn(X).squeeze()\n\n        # compute kernel\n        k = self.kernel(\n            X, X,\n            {\"ell_f\": length, \"sigma_f\": scale},\n            noise\n        )\n        # sample y according to the standard Gaussian process formula\n        numpyro.sample(\n            \"y\",\n            dist.MultivariateNormal(loc=f_loc, covariance_matrix=k),\n            obs=y,\n        )\n\n    def fit(self, rng_key, X, y,\n            num_warmup=2000, num_samples=2000, num_chains=1,\n            progress_bar=True, print_summary=True):\n        \"\"\"\n        Run MCMC to infer the GP model parameters\n        \"\"\"\n        X = X if X.ndim &gt; 1 else X[:, None]\n        self.X_train = X\n        self.y_train = y\n\n        init_strategy = numpyro.infer.init_to_median(num_samples=10)\n        kernel = NUTS(self.model, init_strategy=init_strategy)\n        self.mcmc = MCMC(\n            kernel,\n            num_warmup=num_warmup,\n            num_samples=num_samples,\n            num_chains=num_chains,\n            progress_bar=progress_bar,\n            jit_model_args=False\n        )\n        self.mcmc.run(rng_key, X, y)\n        if print_summary:\n            self.mcmc.print_summary()\n\n    def get_samples(self, chain_dim=False):\n        \"\"\"Get posterior samples (after running the MCMC chains)\"\"\"\n        return self.mcmc.get_samples(group_by_chain=chain_dim)\n\n    @partial(jit, static_argnames='self')\n    def get_mvn_posterior(self, X_test, params):\n        \"\"\"\n        Returns parameters (mean and cov) of multivariate normal posterior\n        for a single sample of GP hyperparameters\n        \"\"\"\n        noise = params[\"noise\"]\n        y_residual = self.y_train\n        if self.mean_fn is not None:\n            y_residual -= self.mean_fn(self.X_train).squeeze()\n            # y_residual -= self.mean_fn(self.X_train, params).squeeze()\n\n        # compute kernel matrices for train and test data\n        k_pp = self.kernel(X_test, X_test, params, noise)\n        k_pX = self.kernel(X_test, self.X_train, params, jitter=0.0)\n        k_XX = self.kernel(self.X_train, self.X_train, params, noise)\n\n        # compute the predictive covariance and mean\n        K_xx_inv = jnp.linalg.inv(k_XX)\n        cov = k_pp - jnp.matmul(k_pX, jnp.matmul(K_xx_inv, jnp.transpose(k_pX)))\n        mean = jnp.matmul(k_pX, jnp.matmul(K_xx_inv, y_residual))\n\n        if self.mean_fn is not None:\n            mean += self.mean_fn(X_test).squeeze()\n            # mean += self.mean_fn(X_test, params).squeeze()\n        return mean, cov\n\n    def _predict(self, rng_key, X_test, params, n):\n        \"\"\"Prediction with a single sample of GP hyperparameters\"\"\"\n        X_test = X_test if X_test.ndim &gt; 1 else X_test[:, None]\n\n        # Get the predictive mean and covariance\n        y_mean, K = self.get_mvn_posterior(X_test, params)\n\n        # draw samples from the posterior predictive for a given set of hyperparameters\n        y_sample = dist.MultivariateNormal(y_mean, K).sample(rng_key, sample_shape=(n,))\n\n        return y_mean, y_sample.squeeze()\n\n    def predict(self, rng_key, X_test, samples=None, n=1):\n        \"\"\"Make prediction at X_test points using sampled GP hyperparameters\"\"\"\n        if samples is None:\n            samples = self.get_samples(chain_dim=False)\n        num_samples = samples[\"ell_f\"].shape[0]\n\n        # use vmap for 'vectorization'\n        vmap_args = (jra.split(rng_key, num_samples), samples)\n        predictive = jax.vmap(lambda params: self._predict(params[0], X_test, params[1], n))\n\n        y_means, y_sampled = predictive(vmap_args)\n\n        return y_means.mean(0), y_sampled\n</code></pre>"},{"location":"stats/#cosmo_ml_tools.stats.gp.GaussianProcessJax.__init__","title":"<code>__init__(self, kernel, input_dim, mean_fn=None)</code>  <code>special</code>","text":"<p>Base Class implementing the usual Gaussian Process Regression algorithm.  The GP posterior is sampled using the Hamiltonian Monte Carlo 'No-U Turn' Sampler (NUTS) as implemented in numpyro e.g. BaseGP(input_dim=2, kernel=RBFKernel)</p> Source code in <code>cosmo_ml_tools/stats/gp.py</code> <pre><code>def __init__(self, kernel, input_dim: int, mean_fn=None): \n    \"\"\"\n    Base Class implementing the usual Gaussian Process Regression algorithm. \n    The GP posterior is sampled using the Hamiltonian Monte Carlo 'No-U Turn' Sampler (NUTS) as implemented in numpyro\n    e.g. BaseGP(input_dim=2, kernel=RBFKernel)\n    \"\"\"\n    # clear_cache()\n    self.input_dim = input_dim\n    self.kernel = kernel\n    self.mean_fn = mean_fn\n    self.X_train = None\n    self.y_train = None\n    self.mcmc = None\n</code></pre>"},{"location":"stats/#cosmo_ml_tools.stats.gp.GaussianProcessJax.fit","title":"<code>fit(self, rng_key, X, y, num_warmup=2000, num_samples=2000, num_chains=1, progress_bar=True, print_summary=True)</code>","text":"<p>Run MCMC to infer the GP model parameters</p> Source code in <code>cosmo_ml_tools/stats/gp.py</code> <pre><code>def fit(self, rng_key, X, y,\n        num_warmup=2000, num_samples=2000, num_chains=1,\n        progress_bar=True, print_summary=True):\n    \"\"\"\n    Run MCMC to infer the GP model parameters\n    \"\"\"\n    X = X if X.ndim &gt; 1 else X[:, None]\n    self.X_train = X\n    self.y_train = y\n\n    init_strategy = numpyro.infer.init_to_median(num_samples=10)\n    kernel = NUTS(self.model, init_strategy=init_strategy)\n    self.mcmc = MCMC(\n        kernel,\n        num_warmup=num_warmup,\n        num_samples=num_samples,\n        num_chains=num_chains,\n        progress_bar=progress_bar,\n        jit_model_args=False\n    )\n    self.mcmc.run(rng_key, X, y)\n    if print_summary:\n        self.mcmc.print_summary()\n</code></pre>"},{"location":"stats/#cosmo_ml_tools.stats.gp.GaussianProcessJax.get_mvn_posterior","title":"<code>get_mvn_posterior(self, X_test, params)</code>","text":"<p>Returns parameters (mean and cov) of multivariate normal posterior for a single sample of GP hyperparameters</p> Source code in <code>cosmo_ml_tools/stats/gp.py</code> <pre><code>@partial(jit, static_argnames='self')\ndef get_mvn_posterior(self, X_test, params):\n    \"\"\"\n    Returns parameters (mean and cov) of multivariate normal posterior\n    for a single sample of GP hyperparameters\n    \"\"\"\n    noise = params[\"noise\"]\n    y_residual = self.y_train\n    if self.mean_fn is not None:\n        y_residual -= self.mean_fn(self.X_train).squeeze()\n        # y_residual -= self.mean_fn(self.X_train, params).squeeze()\n\n    # compute kernel matrices for train and test data\n    k_pp = self.kernel(X_test, X_test, params, noise)\n    k_pX = self.kernel(X_test, self.X_train, params, jitter=0.0)\n    k_XX = self.kernel(self.X_train, self.X_train, params, noise)\n\n    # compute the predictive covariance and mean\n    K_xx_inv = jnp.linalg.inv(k_XX)\n    cov = k_pp - jnp.matmul(k_pX, jnp.matmul(K_xx_inv, jnp.transpose(k_pX)))\n    mean = jnp.matmul(k_pX, jnp.matmul(K_xx_inv, y_residual))\n\n    if self.mean_fn is not None:\n        mean += self.mean_fn(X_test).squeeze()\n        # mean += self.mean_fn(X_test, params).squeeze()\n    return mean, cov\n</code></pre>"},{"location":"stats/#cosmo_ml_tools.stats.gp.GaussianProcessJax.get_samples","title":"<code>get_samples(self, chain_dim=False)</code>","text":"<p>Get posterior samples (after running the MCMC chains)</p> Source code in <code>cosmo_ml_tools/stats/gp.py</code> <pre><code>def get_samples(self, chain_dim=False):\n    \"\"\"Get posterior samples (after running the MCMC chains)\"\"\"\n    return self.mcmc.get_samples(group_by_chain=chain_dim)\n</code></pre>"},{"location":"stats/#cosmo_ml_tools.stats.gp.GaussianProcessJax.model","title":"<code>model(self, X, y)</code>","text":"<p>GP model</p> Source code in <code>cosmo_ml_tools/stats/gp.py</code> <pre><code>def model(self, X, y):\n    \"\"\"GP model\"\"\"\n    # Initialize mean function at zeros\n    f_loc = jnp.zeros(X.shape[0])\n\n    # Sample kernel parameters and noise\n    with numpyro.plate('k_param', self.input_dim):  # allows using ARD kernel for input_dim &gt; 1\n        length = numpyro.sample(\"ell_f\", dist.LogNormal(0.0, 1.0))\n    scale = numpyro.sample(\"sigma_f\", dist.LogNormal(0.0, 1.0))\n    noise = numpyro.sample(\"noise\", dist.LogNormal(0.0, 1.0))\n\n    # Add mean function (if any)\n    if self.mean_fn is not None:\n        f_loc += self.mean_fn(X).squeeze()\n\n    # compute kernel\n    k = self.kernel(\n        X, X,\n        {\"ell_f\": length, \"sigma_f\": scale},\n        noise\n    )\n    # sample y according to the standard Gaussian process formula\n    numpyro.sample(\n        \"y\",\n        dist.MultivariateNormal(loc=f_loc, covariance_matrix=k),\n        obs=y,\n    )\n</code></pre>"},{"location":"stats/#cosmo_ml_tools.stats.gp.GaussianProcessJax.predict","title":"<code>predict(self, rng_key, X_test, samples=None, n=1)</code>","text":"<p>Make prediction at X_test points using sampled GP hyperparameters</p> Source code in <code>cosmo_ml_tools/stats/gp.py</code> <pre><code>def predict(self, rng_key, X_test, samples=None, n=1):\n    \"\"\"Make prediction at X_test points using sampled GP hyperparameters\"\"\"\n    if samples is None:\n        samples = self.get_samples(chain_dim=False)\n    num_samples = samples[\"ell_f\"].shape[0]\n\n    # use vmap for 'vectorization'\n    vmap_args = (jra.split(rng_key, num_samples), samples)\n    predictive = jax.vmap(lambda params: self._predict(params[0], X_test, params[1], n))\n\n    y_means, y_sampled = predictive(vmap_args)\n\n    return y_means.mean(0), y_sampled\n</code></pre>"},{"location":"stats/#cosmo_ml_tools.stats.likelihood","title":"<code>likelihood</code>","text":""},{"location":"stats/#cosmo_ml_tools.stats.likelihood.Likelihood","title":"<code> Likelihood            (LikelihoodBase)         </code>","text":"<p>General Likelihood Class</p> Source code in <code>cosmo_ml_tools/stats/likelihood.py</code> <pre><code>class Likelihood(LikelihoodBase):\n    \"\"\"General Likelihood Class\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n    def ln_prob(self,*args,**kwargs):\n        return -0.5 * self.chi(*args,**kwargs)\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>To use cosmo-ml-tools in a project:</p> <pre><code>import cosmo_ml_tools\n</code></pre>"},{"location":"utils/","title":"Utilities module","text":"<p>Utilities module.</p>"},{"location":"utils/#cosmo_ml_tools.utils.table","title":"<code>table</code>","text":""},{"location":"utils/#cosmo_ml_tools.utils.table.get_latex_table","title":"<code>get_latex_table(samples, parameters, param_labels=None)</code>","text":"<p>Get a latex table with mean and 68% credible intervals constraints for a given set of chains and cosmological parameters.</p> <p>samples: dictionary, a dictionary with getdist instances with the chains.  The corresponding dictionary keys are used as labels.</p> <p>parameters: list, a list with parameter names you want to include in the table</p> <p>param_labels: list (optional), a list with latex names for each of the requested parameters.  If none, its name on the chain is used.</p> Source code in <code>cosmo_ml_tools/utils/table.py</code> <pre><code>def get_latex_table(samples,parameters,param_labels=None):\n    \"\"\"\n    Get a latex table with mean and 68% credible intervals constraints for a given set of chains and cosmological parameters.\n\n    samples: dictionary, a dictionary with getdist instances with the chains. \n    The corresponding dictionary keys are used as labels.\n\n    parameters: list, a list with parameter names you want to include in the table\n\n    param_labels: list (optional), a list with latex names for each of the requested parameters. \n    If none, its name on the chain is used.\n\n    \"\"\"\n    Nparams=len(parameters)\n    cols='l'+'c' * Nparams\n\n    print(r'\\begin{table*}[t]')\n    print(r'\\caption{68\\% credible intervals for the cosmological parameters,\\\n        using various dataset combinations.','\\n',r'\\vspace{0.5em}}')\n    print(r'\\label{tab:tab_label}')\n    print(r'\\centering')\n    print(r'\\small')\n    print(r'\\resizebox{0.95\\textwidth}{!}{')\n    print(r'\\begin{tabular}'+r'{%s}'%cols)\n    print(r'\\toprule')\n    print(r'\\toprule')\n    line='Dataset'\n    params=parameters if param_labels is None else param_labels\n    for p in params:\n        line+=f' &amp; {p}'\n    print(line+r' \\\\')\n    print(r'\\midrule[1.5pt]')\n    for lbl,chain in samples.items():\n        line=f'{lbl}'   \n        for p in parameters:\n            stats=chain.getInlineLatex(p,limit=1).split('=')[1].strip()\n            line+=f' &amp; ${stats}$ '\n        print(line+r' \\\\')\n        if lbl != list(samples.keys())[-1]: print(r'\\midrule')\n    print(r'\\toprule')\n    print(r'\\toprule')\n    print(r'\\end{tabular}}')\n    print(r'\\end{table*}')\n</code></pre>"},{"location":"workflows/","title":"Workflows module","text":"<p>Workflows module.</p>"},{"location":"examples/model_selection/","title":"Model selection","text":"In\u00a0[\u00a0]: Copied!"},{"location":"examples/model_selection/#bayesian-evidence-computation-and-model-selection-with-cobaya-harmonic","title":"Bayesian Evidence Computation and Model Selection with <code>Cobaya</code> &amp; <code>Harmonic</code>\u00b6","text":""}]}